{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b8baa29",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "098ee8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "import numpy as np\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd6875e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/suzukikenta/.cache/kagglehub/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews/versions/1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "data = pd.read_csv(\"/Users/suzukikenta/.cache/kagglehub/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews/versions/1/IMDB Dataset.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31744f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentiment'] = data['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "max_vocab_size = 10000  # Top 10,000 most common words\n",
    "max_sequence_length = 200  # Cut or pad all reviews to 200 words\n",
    "tokenizer = Tokenizer(num_words=max_vocab_size, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(data['review'])  # Fit on all reviews (train + test)\n",
    "# Convert training and test sets into sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b037b98",
   "metadata": {},
   "source": [
    "# RNN_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d356c387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Tune embedding dimension\n",
    "    embedding_dim = hp.Choice('embedding_dim', values=[50, 100, 150])\n",
    "    model.add(Embedding(input_dim=max_vocab_size, output_dim=embedding_dim, input_length=max_sequence_length))\n",
    "\n",
    "    # Tune number of LSTM units\n",
    "    lstm_units = hp.Int('lstm_units', min_value=32, max_value=128, step=32)\n",
    "    model.add(LSTM(lstm_units))\n",
    "\n",
    "    # Tune dropout rate\n",
    "    dropout_rate = hp.Float('dropout_rate', min_value=0.1, max_value=0.5, step=0.1)\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Tune optimizer choice\n",
    "    optimizer = hp.Choice('optimizer', values=['adam', 'rmsprop'])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "04cce591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 02m 06s]\n",
      "val_accuracy: 0.8593000173568726\n",
      "\n",
      "Best val_accuracy So Far: 0.8989999890327454\n",
      "Total elapsed time: 00h 43m 33s\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,             # Number of models to try\n",
    "    executions_per_trial=1,    # How many times to train each model (average performance)\n",
    "    directory='tuner_dir',\n",
    "    project_name='imdb_sentiment'\n",
    ")\n",
    "\n",
    "# Run the search\n",
    "tuner.search(\n",
    "    x_train, train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(x_test, test_labels)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a0f49b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:\n",
      "Embedding dim: 150\n",
      "LSTM units: 96\n",
      "Dropout rate: 0.1\n",
      "Optimizer: adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suzukikenta/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 14 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Best hyperparameters:\")\n",
    "print(f\"Embedding dim: {best_hp.get('embedding_dim')}\")\n",
    "print(f\"LSTM units: {best_hp.get('lstm_units')}\")\n",
    "print(f\"Dropout rate: {best_hp.get('dropout_rate')}\")\n",
    "print(f\"Optimizer: {best_hp.get('optimizer')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab79a25",
   "metadata": {},
   "source": [
    "# Try the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "129051c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save(\"rnn_model.h5\")\n",
    "model = load_model(\"rnn_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3f034dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Predicted sentiment: negative (0.0466)\n"
     ]
    }
   ],
   "source": [
    "new_review = [\"It was the worst movie I have ever seen and I really hated it more than any movies\"]\n",
    "\n",
    "# Convert text to sequence of integers\n",
    "sequence = tokenizer.texts_to_sequences(new_review)\n",
    "\n",
    "# Pad the sequence to match training input length (e.g., 200)\n",
    "padded = pad_sequences(sequence, maxlen=200)\n",
    "\n",
    "# Predict\n",
    "prediction = model.predict(padded)\n",
    "\n",
    "# Interpret result\n",
    "sentiment = \"positive\" if prediction[0][0] > 0.5 else \"negative\"\n",
    "print(f\"Predicted sentiment: {sentiment} ({prediction[0][0]:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
